2016-06-28 23:11:59,295 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: STARTUP_MSG: 
/************************************************************
STARTUP_MSG: Starting DataNode
STARTUP_MSG:   host = ronald-lap/127.0.1.1
STARTUP_MSG:   args = []
STARTUP_MSG:   version = 0.21.0
STARTUP_MSG:   classpath = /opt/hadoop-0.21.0/bin/../conf:/usr/lib/jvm/java-7-oracle/lib/tools.jar:/opt/hadoop-0.21.0/bin/..:/opt/hadoop-0.21.0/bin/../hadoop-common-0.21.0.jar:/opt/hadoop-0.21.0/bin/../hadoop-common-test-0.21.0.jar:/opt/hadoop-0.21.0/bin/../hadoop-hdfs-0.21.0.jar:/opt/hadoop-0.21.0/bin/../hadoop-hdfs-0.21.0-sources.jar:/opt/hadoop-0.21.0/bin/../hadoop-hdfs-ant-0.21.0.jar:/opt/hadoop-0.21.0/bin/../hadoop-hdfs-test-0.21.0.jar:/opt/hadoop-0.21.0/bin/../hadoop-hdfs-test-0.21.0-sources.jar:/opt/hadoop-0.21.0/bin/../hadoop-mapred-0.21.0.jar:/opt/hadoop-0.21.0/bin/../hadoop-mapred-0.21.0-sources.jar:/opt/hadoop-0.21.0/bin/../hadoop-mapred-examples-0.21.0.jar:/opt/hadoop-0.21.0/bin/../hadoop-mapred-test-0.21.0.jar:/opt/hadoop-0.21.0/bin/../hadoop-mapred-tools-0.21.0.jar:/opt/hadoop-0.21.0/bin/../lib/ant-1.6.5.jar:/opt/hadoop-0.21.0/bin/../lib/asm-3.2.jar:/opt/hadoop-0.21.0/bin/../lib/aspectjrt-1.6.5.jar:/opt/hadoop-0.21.0/bin/../lib/aspectjtools-1.6.5.jar:/opt/hadoop-0.21.0/bin/../lib/avro-1.3.2.jar:/opt/hadoop-0.21.0/bin/../lib/commons-cli-1.2.jar:/opt/hadoop-0.21.0/bin/../lib/commons-codec-1.4.jar:/opt/hadoop-0.21.0/bin/../lib/commons-el-1.0.jar:/opt/hadoop-0.21.0/bin/../lib/commons-httpclient-3.1.jar:/opt/hadoop-0.21.0/bin/../lib/commons-lang-2.5.jar:/opt/hadoop-0.21.0/bin/../lib/commons-logging-1.1.1.jar:/opt/hadoop-0.21.0/bin/../lib/commons-logging-api-1.1.jar:/opt/hadoop-0.21.0/bin/../lib/commons-net-1.4.1.jar:/opt/hadoop-0.21.0/bin/../lib/core-3.1.1.jar:/opt/hadoop-0.21.0/bin/../lib/ftplet-api-1.0.0.jar:/opt/hadoop-0.21.0/bin/../lib/ftpserver-core-1.0.0.jar:/opt/hadoop-0.21.0/bin/../lib/ftpserver-deprecated-1.0.0-M2.jar:/opt/hadoop-0.21.0/bin/../lib/hsqldb-1.8.0.10.jar:/opt/hadoop-0.21.0/bin/../lib/jackson-core-asl-1.4.2.jar:/opt/hadoop-0.21.0/bin/../lib/jackson-mapper-asl-1.4.2.jar:/opt/hadoop-0.21.0/bin/../lib/jasper-compiler-5.5.12.jar:/opt/hadoop-0.21.0/bin/../lib/jasper-runtime-5.5.12.jar:/opt/hadoop-0.21.0/bin/../lib/jdiff-1.0.9.jar:/opt/hadoop-0.21.0/bin/../lib/jets3t-0.7.1.jar:/opt/hadoop-0.21.0/bin/../lib/jetty-6.1.14.jar:/opt/hadoop-0.21.0/bin/../lib/jetty-util-6.1.14.jar:/opt/hadoop-0.21.0/bin/../lib/jsp-2.1-6.1.14.jar:/opt/hadoop-0.21.0/bin/../lib/jsp-api-2.1-6.1.14.jar:/opt/hadoop-0.21.0/bin/../lib/junit-4.8.1.jar:/opt/hadoop-0.21.0/bin/../lib/kfs-0.3.jar:/opt/hadoop-0.21.0/bin/../lib/log4j-1.2.15.jar:/opt/hadoop-0.21.0/bin/../lib/mina-core-2.0.0-M5.jar:/opt/hadoop-0.21.0/bin/../lib/mockito-all-1.8.2.jar:/opt/hadoop-0.21.0/bin/../lib/oro-2.0.8.jar:/opt/hadoop-0.21.0/bin/../lib/paranamer-2.2.jar:/opt/hadoop-0.21.0/bin/../lib/paranamer-ant-2.2.jar:/opt/hadoop-0.21.0/bin/../lib/paranamer-generator-2.2.jar:/opt/hadoop-0.21.0/bin/../lib/qdox-1.10.1.jar:/opt/hadoop-0.21.0/bin/../lib/servlet-api-2.5-6.1.14.jar:/opt/hadoop-0.21.0/bin/../lib/slf4j-api-1.5.11.jar:/opt/hadoop-0.21.0/bin/../lib/slf4j-log4j12-1.5.11.jar:/opt/hadoop-0.21.0/bin/../lib/xmlenc-0.52.jar:/opt/hadoop-0.21.0/bin/../lib/jsp-2.1/*.jar:/opt/hadoop-0.21.0/hdfs/bin/../conf:/opt/hadoop-0.21.0/hdfs/bin/../hadoop-hdfs-*.jar:/opt/hadoop-0.21.0/hdfs/bin/../lib/*.jar:/opt/hadoop-0.21.0/bin/../mapred/conf:/opt/hadoop-0.21.0/bin/../mapred/hadoop-mapred-*.jar:/opt/hadoop-0.21.0/bin/../mapred/lib/*.jar:/opt/hadoop-0.21.0/hdfs/bin/../hadoop-hdfs-*.jar:/opt/hadoop-0.21.0/hdfs/bin/../lib/*.jar
STARTUP_MSG:   build = https://svn.apache.org/repos/asf/hadoop/common/branches/branch-0.21 -r 985326; compiled by 'tomwhite' on Tue Aug 17 01:02:28 EDT 2010
************************************************************/
2016-06-28 23:11:59,364 WARN org.apache.hadoop.hdfs.server.common.Util: Path /opt/hadoop-0.21.0/dfs/data should be specified as a URI in configuration files. Please update hdfs configuration.
2016-06-28 23:11:59,457 INFO org.apache.hadoop.security.Groups: Group mapping impl=org.apache.hadoop.security.ShellBasedUnixGroupsMapping; cacheTimeout=300000
2016-06-28 23:11:59,571 INFO org.apache.hadoop.hdfs.server.common.Storage: Storage directory /opt/hadoop-0.21.0/dfs/data is not formatted.
2016-06-28 23:11:59,571 INFO org.apache.hadoop.hdfs.server.common.Storage: Formatting ...
2016-06-28 23:11:59,855 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Registered FSDatasetStatusMBean
2016-06-28 23:11:59,857 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Opened info server at 51010
2016-06-28 23:11:59,860 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Balancing bandwith is 1048576 bytes/s
2016-06-28 23:11:59,866 INFO org.apache.hadoop.hdfs.server.datanode.DirectoryScanner: scan starts at 1467187862866 with interval 21600000
2016-06-28 23:11:59,962 INFO org.mortbay.log: Logging to org.slf4j.impl.Log4jLoggerAdapter(org.mortbay.log) via org.mortbay.log.Slf4jLog
2016-06-28 23:12:00,005 INFO org.apache.hadoop.http.HttpServer: Added global filtersafety (class=org.apache.hadoop.http.HttpServer$QuotingInputFilter)
2016-06-28 23:12:00,010 INFO org.apache.hadoop.http.HttpServer: Port returned by webServer.getConnectors()[0].getLocalPort() before open() is -1. Opening the listener on 51075
2016-06-28 23:12:00,010 INFO org.apache.hadoop.http.HttpServer: listener.getLocalPort() returned 51075 webServer.getConnectors()[0].getLocalPort() returned 51075
2016-06-28 23:12:00,010 INFO org.apache.hadoop.http.HttpServer: Jetty bound to port 51075
2016-06-28 23:12:00,010 INFO org.mortbay.log: jetty-6.1.14
2016-06-28 23:12:00,244 INFO org.mortbay.log: Started SelectChannelConnector@0.0.0.0:51075
2016-06-28 23:12:00,247 INFO org.apache.hadoop.metrics.jvm.JvmMetrics: Initializing JVM Metrics with processName=DataNode, sessionId=null
2016-06-28 23:12:00,294 INFO org.apache.hadoop.ipc.Server: Starting SocketReader
2016-06-28 23:12:00,294 INFO org.apache.hadoop.ipc.metrics.RpcMetrics: Initializing RPC Metrics with hostName=DataNode, port=51020
2016-06-28 23:12:00,295 INFO org.apache.hadoop.ipc.metrics.RpcDetailedMetrics: Initializing RPC Metrics with hostName=DataNode, port=51020
2016-06-28 23:12:00,297 INFO org.apache.hadoop.ipc.Server: IPC Server Responder: starting
2016-06-28 23:12:00,297 INFO org.apache.hadoop.ipc.Server: IPC Server listener on 51020: starting
2016-06-28 23:12:00,297 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: dnRegistration = DatanodeRegistration(ronald-lap:51010, storageID=, infoPort=51075, ipcPort=51020)
2016-06-28 23:12:00,297 INFO org.apache.hadoop.ipc.Server: IPC Server handler 1 on 51020: starting
2016-06-28 23:12:00,298 INFO org.apache.hadoop.ipc.Server: IPC Server handler 0 on 51020: starting
2016-06-28 23:12:00,298 INFO org.apache.hadoop.ipc.Server: IPC Server handler 2 on 51020: starting
2016-06-28 23:12:00,335 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: New storage id DS-1347295268-127.0.1.1-51010-1467173520298 is assigned to data-node 127.0.0.1:51010
2016-06-28 23:12:00,336 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: DatanodeRegistration(127.0.0.1:51010, storageID=DS-1347295268-127.0.1.1-51010-1467173520298, infoPort=51075, ipcPort=51020)In DataNode.run, data = FSDataset{dirpath='/opt/hadoop-0.21.0/dfs/data/current/finalized'}
2016-06-28 23:12:00,336 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: using BLOCKREPORT_INTERVAL of 21600000msec Initial delay: 0msec
2016-06-28 23:12:00,342 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: BlockReport of 0 blocks got processed in 5 msecs
2016-06-28 23:12:00,342 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Starting Periodic block scanner.
2016-06-28 23:12:02,852 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving block blk_-6038785587801652367_1001 src: /127.0.0.1:48556 dest: /127.0.0.1:51010
2016-06-28 23:12:02,868 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /127.0.0.1:48556, dest: /127.0.0.1:51010, bytes: 4, op: HDFS_WRITE, cliID: DFSClient_1613142213, offset: 0, srvID: DS-1347295268-127.0.1.1-51010-1467173520298, blockid: blk_-6038785587801652367_1001, duration: 8697814
2016-06-28 23:12:02,868 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder 0 for block blk_-6038785587801652367_1001 terminating
2016-06-28 23:19:43,421 INFO org.apache.hadoop.hdfs.server.datanode.DataBlockScanner: Verification succeeded for blk_-6038785587801652367_1001
